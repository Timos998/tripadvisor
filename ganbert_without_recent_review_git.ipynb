{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/github/crux82/ganbert-pytorch/blob/main/GANBERT_pytorch.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUpqAwtN8rTA"
   },
   "source": [
    "# GAN-BERT (in Pytorch and compatible with HuggingFace)\n",
    "\n",
    "This is a Pytorch (+ **Huggingface** transformers) implementation of the GAN-BERT model from https://github.com/crux82/ganbert. While the original GAN-BERT was an extension of BERT, this implementation can be adapted to several architectures, ranging from Roberta to Albert!\n",
    "\n",
    "**NOTE**: given that this implementation is different from the original one in Tensorflow, some results can be slighty different.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0m5KR34gmRH"
   },
   "source": [
    "Let's GO!\n",
    "\n",
    "Required Imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting libtpu-nightly@ https://storage.googleapis.com/cloud-tpu-tpuvm-artifacts/wheels/libtpu-nightly/libtpu_nightly-0.1.dev20211013-py3-none-any.whl\n",
      "  Using cached https://storage.googleapis.com/cloud-tpu-tpuvm-artifacts/wheels/libtpu-nightly/libtpu_nightly-0.1.dev20211013-py3-none-any.whl (138.9 MB)\n",
      "Collecting lm-eval@ git+https://github.com/EleutherAI/lm-evaluation-harness/@b0acb3379d2fa8e15561cea033be422bff144f30\n",
      "  Using cached lm_eval-0.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: absl-py==0.12.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 1)) (0.12.0)\n",
      "Requirement already satisfied: aiohttp==3.8.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 2)) (3.8.1)\n",
      "Requirement already satisfied: aiohttp-cors==0.7.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: aioredis==2.0.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 4)) (2.0.1)\n",
      "Requirement already satisfied: aiosignal==1.2.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: anyio==3.6.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 6)) (3.6.1)\n",
      "Requirement already satisfied: appdirs==1.4.4 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 7)) (1.4.4)\n",
      "Requirement already satisfied: asgiref==3.5.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 8)) (3.5.2)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 9)) (1.6.3)\n",
      "Requirement already satisfied: async-timeout==4.0.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 10)) (4.0.2)\n",
      "Requirement already satisfied: attrs==19.3.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 11)) (19.3.0)\n",
      "Requirement already satisfied: Automat==0.8.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 12)) (0.8.0)\n",
      "Requirement already satisfied: bcrypt==3.2.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 13)) (3.2.2)\n",
      "Requirement already satisfied: blessings==1.7 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 14)) (1.7)\n",
      "Requirement already satisfied: blinker==1.4 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 16)) (1.4)\n",
      "Requirement already satisfied: cachetools==4.2.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 17)) (4.2.2)\n",
      "Requirement already satisfied: certifi==2020.12.5 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 18)) (2020.12.5)\n",
      "Requirement already satisfied: cffi==1.15.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 19)) (1.15.0)\n",
      "Requirement already satisfied: chardet==4.0.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 20)) (4.0.0)\n",
      "Requirement already satisfied: charset-normalizer==2.0.12 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 21)) (2.0.12)\n",
      "Requirement already satisfied: chex==0.1.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 22)) (0.1.1)\n",
      "Requirement already satisfied: clang==5.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 23)) (5.0)\n",
      "Requirement already satisfied: click==7.1.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 24)) (7.1.2)\n",
      "Requirement already satisfied: cloud-tpu-client==0.10 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 26)) (0.10)\n",
      "Requirement already satisfied: cloudpickle==1.3.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 27)) (1.3.0)\n",
      "Requirement already satisfied: colorama==0.4.3 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 28)) (0.4.3)\n",
      "Requirement already satisfied: colorful==0.5.4 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 29)) (0.5.4)\n",
      "Requirement already satisfied: configobj==5.0.6 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 31)) (5.0.6)\n",
      "Requirement already satisfied: constantly==15.1.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 32)) (15.1.0)\n",
      "Requirement already satisfied: cryptography==2.8 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 33)) (2.8)\n",
      "Requirement already satisfied: Cython==0.29.23 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 34)) (0.29.23)\n",
      "Requirement already satisfied: DataProperty==0.55.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 35)) (0.55.0)\n",
      "Requirement already satisfied: datasets==2.2.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 36)) (2.2.2)\n",
      "Requirement already satisfied: Deprecated==1.2.13 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 38)) (1.2.13)\n",
      "Requirement already satisfied: dill==0.3.4 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 39)) (0.3.4)\n",
      "Requirement already satisfied: distlib==0.3.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 40)) (0.3.1)\n",
      "Requirement already satisfied: distro==1.4.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 41)) (1.4.0)\n",
      "Requirement already satisfied: dm-haiku==0.0.5 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 43)) (0.0.5)\n",
      "Requirement already satisfied: dm-tree==0.1.7 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 44)) (0.1.7)\n",
      "Requirement already satisfied: docker-pycreds==0.4.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 45)) (0.4.0)\n",
      "Requirement already satisfied: dyNET38==2.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 46)) (2.1)\n",
      "Requirement already satisfied: einops==0.3.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 47)) (0.3.2)\n",
      "Requirement already satisfied: entrypoints==0.3 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 48)) (0.3)\n",
      "Requirement already satisfied: fabric==2.6.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 49)) (2.6.0)\n",
      "Requirement already satisfied: fastapi==0.73.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 50)) (0.73.0)\n",
      "Requirement already satisfied: filelock==3.0.12 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 51)) (3.0.12)\n",
      "Requirement already satisfied: Flask==1.1.4 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 52)) (1.1.4)\n",
      "Requirement already satisfied: flatbuffers==1.12 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 53)) (1.12)\n",
      "Requirement already satisfied: frozenlist==1.3.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 54)) (1.3.0)\n",
      "Requirement already satisfied: fsspec==2022.5.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 55)) (2022.5.0)\n",
      "Requirement already satisfied: ftfy==6.1.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 56)) (6.1.1)\n",
      "Requirement already satisfied: func-timeout==4.3.5 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 57)) (4.3.5)\n",
      "Requirement already satisfied: future==0.18.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 58)) (0.18.2)\n",
      "Requirement already satisfied: gast==0.4.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 59)) (0.4.0)\n",
      "Requirement already satisfied: gitdb==4.0.9 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 60)) (4.0.9)\n",
      "Requirement already satisfied: GitPython==3.1.27 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 61)) (3.1.27)\n",
      "Requirement already satisfied: google-api-core==1.28.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 62)) (1.28.0)\n",
      "Requirement already satisfied: google-api-python-client==1.8.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 63)) (1.8.0)\n",
      "Requirement already satisfied: google-auth==1.30.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 64)) (1.30.1)\n",
      "Requirement already satisfied: google-auth-httplib2==0.1.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 65)) (0.1.0)\n",
      "Requirement already satisfied: google-auth-oauthlib==0.4.4 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 66)) (0.4.4)\n",
      "Requirement already satisfied: google-cloud-core==1.7.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 67)) (1.7.2)\n",
      "Requirement already satisfied: google-cloud-storage==1.36.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 68)) (1.36.2)\n",
      "Requirement already satisfied: google-crc32c==1.3.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 69)) (1.3.0)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 70)) (0.2.0)\n",
      "Requirement already satisfied: google-resumable-media==1.3.3 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 71)) (1.3.3)\n",
      "Requirement already satisfied: googleapis-common-protos==1.53.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 72)) (1.53.0)\n",
      "Requirement already satisfied: gpustat==0.6.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 73)) (0.6.0)\n",
      "Requirement already satisfied: grpcio==1.46.3 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 74)) (1.46.3)\n",
      "Requirement already satisfied: h11==0.13.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 75)) (0.13.0)\n",
      "Requirement already satisfied: h5py==3.1.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 76)) (3.1.0)\n",
      "Requirement already satisfied: httplib2==0.19.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 77)) (0.19.1)\n",
      "Requirement already satisfied: huggingface-hub==0.7.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 78)) (0.7.0)\n",
      "Requirement already satisfied: hyperlink==19.0.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 79)) (19.0.0)\n",
      "Requirement already satisfied: idna==2.10 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 80)) (2.10)\n",
      "Requirement already satisfied: importlib-metadata==1.5.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 81)) (1.5.0)\n",
      "Requirement already satisfied: incremental==16.10.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 82)) (16.10.1)\n",
      "Requirement already satisfied: invoke==1.7.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 83)) (1.7.1)\n",
      "Requirement already satisfied: itsdangerous==1.1.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 84)) (1.1.0)\r\n",
      "Requirement already satisfied: jax==0.2.12 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 85)) (0.2.12)\r\n",
      "Requirement already satisfied: jaxlib==0.1.67 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 86)) (0.1.67)\r\n",
      "Requirement already satisfied: jieba==0.42.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 87)) (0.42.1)\r\n",
      "Requirement already satisfied: Jinja2==2.10.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 88)) (2.10.1)\r\n",
      "Requirement already satisfied: jmp==0.0.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 89)) (0.0.2)\r\n",
      "Requirement already satisfied: joblib==1.1.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 90)) (1.1.0)\r\n",
      "Requirement already satisfied: jsonlines==2.0.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 91)) (2.0.0)\r\n",
      "Requirement already satisfied: jsonpatch==1.22 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 92)) (1.22)\r\n",
      "Requirement already satisfied: jsonpointer==2.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 93)) (2.0)\r\n",
      "Requirement already satisfied: jsonschema==3.2.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 94)) (3.2.0)\r\n",
      "Requirement already satisfied: keras==2.6.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 95)) (2.6.0)\r\n",
      "Requirement already satisfied: Keras-Applications==1.0.8 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 96)) (1.0.8)\r\n",
      "Requirement already satisfied: keras-nightly==2.5.0.dev2021032900 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 97)) (2.5.0.dev2021032900)\r\n",
      "Requirement already satisfied: Keras-Preprocessing==1.1.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 98)) (1.1.2)\r\n",
      "Requirement already satisfied: keyring==18.0.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 99)) (18.0.1)\r\n",
      "Requirement already satisfied: launchpadlib==1.10.13 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 101)) (1.10.13)\r\n",
      "Requirement already satisfied: lazr.restfulclient==0.14.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 102)) (0.14.2)\r\n",
      "Requirement already satisfied: lazr.uri==1.0.3 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 103)) (1.0.3)\r\n",
      "Requirement already satisfied: lm-dataformat==0.0.20 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 105)) (0.0.20)\r\n",
      "Requirement already satisfied: Markdown==3.3.4 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 107)) (3.3.4)\r\n",
      "Requirement already satisfied: MarkupSafe==1.1.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 108)) (1.1.0)\r\n",
      "Requirement already satisfied: mbstrdecoder==1.1.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 109)) (1.1.0)\r\n",
      "Requirement already satisfied: mock==4.0.3 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 110)) (4.0.3)\r\n",
      "Requirement already satisfied: more-itertools==4.2.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 111)) (4.2.0)\r\n",
      "Requirement already satisfied: msgfy==0.2.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 112)) (0.2.0)\r\n",
      "Requirement already satisfied: msgpack==1.0.3 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 113)) (1.0.3)\r\n",
      "Requirement already satisfied: multidict==6.0.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 114)) (6.0.2)\r\n",
      "Requirement already satisfied: multiprocess==0.70.12.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 115)) (0.70.12.2)\r\n",
      "Requirement already satisfied: nagisa==0.2.7 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 116)) (0.2.7)\r\n",
      "Requirement already satisfied: netifaces==0.10.4 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 117)) (0.10.4)\r\n",
      "Requirement already satisfied: nltk==3.7 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 118)) (3.7)\r\n",
      "Requirement already satisfied: numexpr==2.7.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 119)) (2.7.2)\r\n",
      "Requirement already satisfied: numpy==1.19.5 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 120)) (1.19.5)\r\n",
      "Requirement already satisfied: nvidia-ml-py3==7.352.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 121)) (7.352.0)\r\n",
      "Requirement already satisfied: oauth2client==4.1.3 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 122)) (4.1.3)\r\n",
      "Requirement already satisfied: oauthlib==3.1.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 123)) (3.1.0)\r\n",
      "Requirement already satisfied: openai==0.6.4 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 124)) (0.6.4)\r\n",
      "Requirement already satisfied: opencensus==0.9.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 125)) (0.9.0)\r\n",
      "Requirement already satisfied: opencensus-context==0.1.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 126)) (0.1.2)\r\n",
      "Requirement already satisfied: opt-einsum==3.3.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 127)) (3.3.0)\r\n",
      "Requirement already satisfied: optax==0.0.9 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 128)) (0.0.9)\r\n",
      "Requirement already satisfied: packaging==20.9 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 129)) (20.9)\r\n",
      "Requirement already satisfied: pandas==1.4.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 130)) (1.4.2)\r\n",
      "Requirement already satisfied: paramiko==2.11.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 131)) (2.11.0)\r\n",
      "Requirement already satisfied: pathlib2==2.3.7.post1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 132)) (2.3.7.post1)\r\n",
      "Requirement already satisfied: pathtools==0.1.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 133)) (0.1.2)\r\n",
      "Requirement already satisfied: pathvalidate==2.5.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 134)) (2.5.0)\r\n",
      "Requirement already satisfied: pathy==0.6.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 135)) (0.6.1)\r\n",
      "Requirement already satisfied: pexpect==4.6.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 136)) (4.6.0)\r\n",
      "Requirement already satisfied: Pillow==8.2.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 137)) (8.2.0)\r\n",
      "Requirement already satisfied: portalocker==2.4.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 138)) (2.4.0)\r\n",
      "Requirement already satisfied: prometheus-client==0.14.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 139)) (0.14.1)\r\n",
      "Requirement already satisfied: promise==2.3 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 140)) (2.3)\r\n",
      "Requirement already satisfied: protobuf==3.17.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 141)) (3.17.1)\r\n",
      "Requirement already satisfied: psutil==5.9.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 142)) (5.9.1)\r\n",
      "Requirement already satisfied: py-spy==0.3.12 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 143)) (0.3.12)\r\n",
      "Requirement already satisfied: pyarrow==8.0.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 144)) (8.0.0)\r\n",
      "Requirement already satisfied: pyasn1==0.4.8 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 145)) (0.4.8)\r\n",
      "Requirement already satisfied: pyasn1-modules==0.2.8 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 146)) (0.2.8)\r\n",
      "Requirement already satisfied: pybind11==2.6.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 147)) (2.6.2)\r\n",
      "Requirement already satisfied: pycountry==20.7.3 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 148)) (20.7.3)\r\n",
      "Requirement already satisfied: pycparser==2.21 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 149)) (2.21)\r\n",
      "Requirement already satisfied: pydantic==1.9.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 150)) (1.9.1)\r\n",
      "Requirement already satisfied: PyHamcrest==1.9.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 152)) (1.9.0)\r\n",
      "Requirement already satisfied: PyJWT==1.7.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 153)) (1.7.1)\r\n",
      "Requirement already satisfied: pymacaroons==0.13.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 154)) (0.13.0)\r\n",
      "Requirement already satisfied: PyNaCl==1.3.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 155)) (1.3.0)\r\n",
      "Requirement already satisfied: pyOpenSSL==19.0.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 156)) (19.0.0)\r\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 157)) (2.4.7)\r\n",
      "Requirement already satisfied: pyrsistent==0.15.5 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 158)) (0.15.5)\r\n",
      "Requirement already satisfied: pyserial==3.4 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 159)) (3.4)\r\n",
      "Requirement already satisfied: pytablewriter==0.58.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 160)) (0.58.0)\r\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 162)) (2.8.2)\r\n",
      "Requirement already satisfied: pytz==2021.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 164)) (2021.1)\r\n",
      "Requirement already satisfied: PyYAML==5.4.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 165)) (5.4.1)\r\n",
      "Requirement already satisfied: ray==1.4.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 166)) (1.4.1)\r\n",
      "Requirement already satisfied: redis==4.3.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 167)) (4.3.2)\r\n",
      "Requirement already satisfied: regex==2022.4.24 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 168)) (2022.4.24)\r\n",
      "Requirement already satisfied: requests==2.25.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 169)) (2.25.1)\r\n",
      "Requirement already satisfied: requests-oauthlib==1.3.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 170)) (1.3.0)\r\n",
      "Requirement already satisfied: requests-unixsocket==0.2.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 171)) (0.2.0)\r\n",
      "Requirement already satisfied: responses==0.18.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 172)) (0.18.0)\r\n",
      "Requirement already satisfied: rouge-score==0.0.4 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 173)) (0.0.4)\r\n",
      "Requirement already satisfied: rsa==4.7.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 174)) (4.7.2)\r\n",
      "Requirement already satisfied: sacrebleu==1.5.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 175)) (1.5.0)\r\n",
      "Requirement already satisfied: sacremoses==0.0.53 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 176)) (0.0.53)\r\n",
      "Requirement already satisfied: scikit-learn==1.1.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 177)) (1.1.1)\r\n",
      "Requirement already satisfied: scipy==1.6.3 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 178)) (1.6.3)\r\n",
      "Requirement already satisfied: SecretStorage==2.3.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 179)) (2.3.1)\r\n",
      "Requirement already satisfied: sentencepiece==0.1.96 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 180)) (0.1.96)\r\n",
      "Requirement already satisfied: sentry-sdk==1.5.12 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 181)) (1.5.12)\r\n",
      "Requirement already satisfied: service-identity==18.1.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 182)) (18.1.0)\r\n",
      "Requirement already satisfied: setproctitle==1.2.3 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 183)) (1.2.3)\r\n",
      "Requirement already satisfied: shortuuid==1.0.9 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 184)) (1.0.9)\r\n",
      "Requirement already satisfied: simplejson==3.16.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 185)) (3.16.0)\r\n",
      "Requirement already satisfied: six==1.15.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 186)) (1.15.0)\r\n",
      "Requirement already satisfied: smart-open==5.2.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 187)) (5.2.1)\r\n",
      "Requirement already satisfied: smmap==5.0.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 188)) (5.0.0)\r\n",
      "Requirement already satisfied: sniffio==1.2.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 189)) (1.2.0)\r\n",
      "Requirement already satisfied: sqlitedict==1.6.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 191)) (1.6.0)\r\n",
      "Requirement already satisfied: ssh-import-id==5.10 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 192)) (5.10)\r\n",
      "Requirement already satisfied: starlette==0.17.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 193)) (0.17.1)\r\n",
      "Requirement already satisfied: tabledata==1.3.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 195)) (1.3.0)\r\n",
      "Requirement already satisfied: tabulate==0.8.9 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 196)) (0.8.9)\r\n",
      "Requirement already satisfied: tb-nightly==2.6.0a20210524 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 197)) (2.6.0a20210524)\r\n",
      "Requirement already satisfied: tcolorpy==0.1.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 198)) (0.1.2)\r\n",
      "Requirement already satisfied: tensorboard==2.6.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 199)) (2.6.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server==0.6.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 200)) (0.6.1)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit==1.8.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 201)) (1.8.0)\r\n",
      "Requirement already satisfied: tensorflow==2.6.5 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 202)) (2.6.5)\r\n",
      "Requirement already satisfied: tensorflow-cpu==2.6.5 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 203)) (2.6.5)\r\n",
      "Requirement already satisfied: tensorflow-estimator==2.6.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 204)) (2.6.0)\r\n",
      "Requirement already satisfied: termcolor==1.1.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 205)) (1.1.0)\r\n",
      "Requirement already satisfied: tf-slim==1.1.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 208)) (1.1.0)\r\n",
      "Requirement already satisfied: threadpoolctl==3.1.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 209)) (3.1.0)\r\n",
      "Requirement already satisfied: tokenizers==0.12.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 210)) (0.12.1)\r\n",
      "Requirement already satisfied: toolz==0.11.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 211)) (0.11.2)\r\n",
      "Requirement already satisfied: torch==1.8.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 212)) (1.8.1)\r\n",
      "Requirement already satisfied: torchvision==0.9.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 214)) (0.9.1)\r\n",
      "Requirement already satisfied: tqdm==4.64.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 215)) (4.64.0)\r\n",
      "Requirement already satisfied: tqdm-multiprocess==0.0.11 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 216)) (0.0.11)\r\n",
      "Requirement already satisfied: transformers==4.16.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 217)) (4.16.2)\r\n",
      "Requirement already satisfied: Twisted==18.9.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 218)) (18.9.0)\r\n",
      "Requirement already satisfied: typepy==1.3.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 219)) (1.3.0)\r\n",
      "Requirement already satisfied: typer==0.4.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 220)) (0.4.1)\r\n",
      "Requirement already satisfied: typing-extensions==3.7.4.3 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 221)) (3.7.4.3)\r\n",
      "Requirement already satisfied: ujson==5.3.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 224)) (5.3.0)\r\n",
      "Requirement already satisfied: uritemplate==3.0.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 226)) (3.0.1)\r\n",
      "Requirement already satisfied: urllib3==1.26.4 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 227)) (1.26.4)\r\n",
      "Requirement already satisfied: uvicorn==0.17.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 228)) (0.17.1)\r\n",
      "Requirement already satisfied: virtualenv==20.4.7 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 229)) (20.4.7)\r\n",
      "Requirement already satisfied: wadllib==1.3.3 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 230)) (1.3.3)\r\n",
      "Requirement already satisfied: wandb==0.12.17 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 231)) (0.12.17)\r\n",
      "Requirement already satisfied: wcwidth==0.2.5 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 232)) (0.2.5)\r\n",
      "Requirement already satisfied: Werkzeug==1.0.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 233)) (1.0.1)\r\n",
      "Requirement already satisfied: wrapt==1.12.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 234)) (1.12.1)\r\n",
      "Requirement already satisfied: xxhash==3.0.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 235)) (3.0.0)\r\n",
      "Requirement already satisfied: yarl==1.7.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 236)) (1.7.2)\r\n",
      "Requirement already satisfied: zipp==1.0.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 237)) (1.0.0)\r\n",
      "Requirement already satisfied: zope.interface==4.7.1 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 238)) (4.7.1)\r\n",
      "Requirement already satisfied: zstandard==0.15.2 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from -r /data/fire.txt (line 239)) (0.15.2)\r\n",
      "Collecting bleurt@ https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip#egg=bleurt\n",
      "  Using cached https://github.com/google-research/bleurt/archive/b610120347ef22b494b6d69b4316e303f5932516.zip\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from astunparse==1.6.3->-r /data/fire.txt (line 9)) (0.36.2)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from google-api-core==1.28.0->-r /data/fire.txt (line 62)) (61.2.0)\n",
      "Requirement already satisfied: testresources in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from launchpadlib==1.10.13->-r /data/fire.txt (line 101)) (2.0.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from pexpect==4.6.0->-r /data/fire.txt (line 136)) (0.7.0)\n",
      "Requirement already satisfied: pbr>=1.8 in /root/anaconda3/envs/pytorch/lib/python3.8/site-packages (from testresources->launchpadlib==1.10.13->-r /data/fire.txt (line 101)) (5.9.0)\n",
      "\"localservice;0;localhost:51011\"\n"
     ]
    }
   ],
   "source": [
    "!pip install -r /data/fire.txt\n",
    "# !pip install tensorflow\n",
    "# !conda install -c conda-forge -y pandas jupyter\n",
    "# !pip install sacremoses\n",
    "# !pip install -U numpy\n",
    "\n",
    "# !conda install numpy\n",
    "# !conda install -c intel mkl\n",
    "\n",
    "# !export XRT_TPU_CONFIG=\"localservice;0;localhost:51011\"\n",
    "!echo $XRT_TPU_CONFIG\n",
    "\n",
    "import os\n",
    "os.environ[]='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export XLA_USE_XRT=1 XRT_DEVICE_MAP=\"\"\n",
    "\n",
    "!export TPU_NAME=life\n",
    "!export TF_CPP_MIN_LOG_LEVEL=0\n",
    "!export XRT_TPU_CONFIG=\"\"\n",
    "!export TF_XLA_FLAGS=--tf_xla_enable_xla_devices\n",
    "\n",
    "# export XRT_DEVICE_MAP=\"\"\n",
    "# export XRT_WORKERS=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UIqpm34x2rms",
    "outputId": "b0205d19-dff1-4967-d003-990c3c5c8164"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.convert_graph_to_onnx because of the following error (look up to see its traceback):\n/root/anaconda3/envs/pytorch/lib/python3.8/site-packages/_XLAC.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZNK5torch4lazy4Node6shapesEv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2703\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2704\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2705\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/convert_graph_to_onnx.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipelines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maudio_classification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioClassificationPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mautomatic_speech_recognition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutomaticSpeechRecognitionPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/pipelines/audio_classification.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIPELINE_INIT_ARGS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_end_docstrings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelcard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfiguration_auto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/modelcard.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m )\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining_args\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallelMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mis_torch_tpu_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torch_xla.core\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/importlib/util.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparent_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfromlist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__path__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_xla/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TPU_LIBRARY_PATH'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/dev/null'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0m_XLAC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /root/anaconda3/envs/pytorch/lib/python3.8/site-packages/_XLAC.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZNK5torch4lazy4Node6shapesEv",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-f41009ea9eed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2690\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2692\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2693\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2706\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2707\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its traceback):\\n{e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m             ) from e\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.convert_graph_to_onnx because of the following error (look up to see its traceback):\n/root/anaconda3/envs/pytorch/lib/python3.8/site-packages/_XLAC.cpython-38-x86_64-linux-gnu.so: undefined symbol: _ZNK5torch4lazy4Node6shapesEv"
     ]
    }
   ],
   "source": [
    "# !pip install sentencepiece\n",
    "# !pip install transformers==4.3.2\n",
    "\n",
    "import torch\n",
    "import io\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "import torch.nn as nn\n",
    "from transformers import *\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "#!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "\n",
    "##Set random values\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "if torch.cuda.is_available():\n",
    "  torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LeZgRup520II",
    "outputId": "5b8d1039-e1e6-4712-e77b-e1e9f1b9fbcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AU3ns8Ic7I-h"
   },
   "source": [
    "### Input Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jw0HC_hU3FUy",
    "outputId": "6ae87fcf-ed0b-4c78-b9aa-7d86d80cb933"
   },
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "#  Transformer parameters\n",
    "#--------------------------------\n",
    "max_seq_length = 64\n",
    "batch_size = 64\n",
    "\n",
    "#--------------------------------\n",
    "#  GAN-BERT specific parameters\n",
    "#--------------------------------\n",
    "# number of hidden layers in the generator, \n",
    "# each of the size of the output space\n",
    "num_hidden_layers_g = 1; \n",
    "# number of hidden layers in the discriminator, \n",
    "# each of the size of the input space\n",
    "num_hidden_layers_d = 1; \n",
    "# size of the generator's input noisy vectors\n",
    "noise_size = 100\n",
    "# dropout to be applied to discriminator's input vectors\n",
    "out_dropout_rate = 0.2\n",
    "\n",
    "# Replicate labeled data to balance poorly represented datasets, \n",
    "# e.g., less than 1% of labeled material\n",
    "apply_balance = True\n",
    "\n",
    "#--------------------------------\n",
    "#  Optimization parameters\n",
    "#--------------------------------\n",
    "learning_rate_discriminator = 5e-5\n",
    "learning_rate_generator = 5e-5\n",
    "epsilon = 1e-8\n",
    "num_train_epochs = 10\n",
    "multi_gpu = True\n",
    "# Scheduler\n",
    "apply_scheduler = False\n",
    "warmup_proportion = 0.1\n",
    "# Print\n",
    "print_each_n_step = 10\n",
    "\n",
    "#--------------------------------\n",
    "#  Adopted Tranformer model\n",
    "#--------------------------------\n",
    "# Since this version is compatible with Huggingface transformers, you can uncomment\n",
    "# (or add) transformer models compatible with GAN\n",
    "\n",
    "model_name = \"bert-base-cased\"\n",
    "#model_name = \"bert-base-uncased\"\n",
    "#model_name = \"roberta-base\"\n",
    "#model_name = \"albert-base-v2\"\n",
    "#model_name = \"xlm-roberta-base\"\n",
    "#model_name = \"amazon/bort\"\n",
    "\n",
    "#--------------------------------\n",
    "#  Retrieve the TREC QC Dataset\n",
    "#--------------------------------\n",
    "# ! git clone https://github.com/crux82/ganbert\n",
    "\n",
    "#  NOTE: in this setting 50 classes are involved\n",
    "labeled_file = \"./ganbert/data/labeled.tsv\" #files for reviews are with _ta1\n",
    "unlabeled_file = \"./ganbert/data/unlabeled.tsv\"\n",
    "test_filename = \"./ganbert/data/test.tsv\"\n",
    "\n",
    "#label_list = [\"UNK\", \"Low\", \"High\"]\n",
    "\n",
    "#[\"UNK_UNK\",\"ABBR_abb\", \"ABBR_exp\", \"DESC_def\", \"DESC_desc\", \n",
    "              #\"DESC_manner\", \"DESC_reason\", \"ENTY_animal\", \"ENTY_body\", \n",
    "              #\"ENTY_color\", \"ENTY_cremat\", \"ENTY_currency\", \"ENTY_dismed\", \n",
    "              #\"ENTY_event\", \"ENTY_food\", \"ENTY_instru\", \"ENTY_lang\", \n",
    "              #\"ENTY_letter\", \"ENTY_other\", \"ENTY_plant\", \"ENTY_product\", \n",
    "              #\"ENTY_religion\", \"ENTY_sport\", \"ENTY_substance\", \"ENTY_symbol\", \n",
    "              #\"ENTY_techmeth\", \"ENTY_termeq\", \"ENTY_veh\", \"ENTY_word\", \"HUM_desc\", \n",
    "              #\"HUM_gr\", \"HUM_ind\", \"HUM_title\", \"LOC_city\", \"LOC_country\", \n",
    "              #\"LOC_mount\", \"LOC_other\", \"LOC_state\", \"NUM_code\", \"NUM_count\", \n",
    "              #\"NUM_date\", \"NUM_dist\", \"NUM_money\", \"NUM_ord\", \"NUM_other\", \n",
    "              #\"NUM_perc\", \"NUM_period\", \"NUM_speed\", \"NUM_temp\", \"NUM_volsize\", \n",
    "              #\"NUM_weight\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>hotel_name</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>helpful_count</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>date_today</th>\n",
       "      <th>days_published</th>\n",
       "      <th>quality</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.tripadvisor.ca/ShowUserReviews-g18...</td>\n",
       "      <td>Novotel Maastricht</td>\n",
       "      <td>A cut above the usual - well worth considering</td>\n",
       "      <td>Stayed here for five nights in mid February. T...</td>\n",
       "      <td>5</td>\n",
       "      <td>2007-02-18</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>5569.0</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.tripadvisor.ca/ShowUserReviews-g18...</td>\n",
       "      <td>citizenM Schiphol Airport</td>\n",
       "      <td>fabulous fun funky</td>\n",
       "      <td>Loved this place. great value.  Rooms very sma...</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-08-11</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>3934.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.tripadvisor.ca/ShowUserReviews-g18...</td>\n",
       "      <td>citizenM Schiphol Airport</td>\n",
       "      <td>Great Concept - awful food</td>\n",
       "      <td>This is a great hotel with a fantastic concept...</td>\n",
       "      <td>5</td>\n",
       "      <td>2008-11-26</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>4922.0</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.tripadvisor.ca/ShowUserReviews-g22...</td>\n",
       "      <td>Ibis Budget Amsterdam Airport</td>\n",
       "      <td>Clean budget hotel</td>\n",
       "      <td>We stayed for two nights in April 2017.  There...</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.tripadvisor.ca/ShowUserReviews-g18...</td>\n",
       "      <td>Bastion Hotel Rotterdam Zuid</td>\n",
       "      <td>Please book else where</td>\n",
       "      <td>Where to start?,We tried to check in one day l...</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-29</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>1816.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>https://www.tripadvisor.ca/ShowUserReviews-g22...</td>\n",
       "      <td>Hampton by Hilton Amsterdam Airport Schiphol</td>\n",
       "      <td>Good deal!</td>\n",
       "      <td>The hotel is far from what you would expect fr...</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-07-25</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>2124.0</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>https://www.tripadvisor.ca/ShowUserReviews-g18...</td>\n",
       "      <td>Holiday Inn Eindhoven, an IHG hotel</td>\n",
       "      <td>Not as good as expected</td>\n",
       "      <td>My review is based on the comparison to other ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-25</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>1636.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>https://www.tripadvisor.ca/ShowUserReviews-g22...</td>\n",
       "      <td>ibis Schiphol Amsterdam Airport</td>\n",
       "      <td>Handy for the airport but a little pricey</td>\n",
       "      <td>This is a very large Ibis.  I paid 129 which ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-05-02</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>4765.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>https://www.tripadvisor.ca/ShowUserReviews-g18...</td>\n",
       "      <td>citizenM Schiphol Airport</td>\n",
       "      <td>Thank you for making things eaier</td>\n",
       "      <td>I arrived with a booking that (unknown to me) ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-24</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>2094.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>https://www.tripadvisor.ca/ShowUserReviews-g18...</td>\n",
       "      <td>Room Mate Bruno</td>\n",
       "      <td>Beyond the expectations </td>\n",
       "      <td>Two days of business offsite were successful m...</td>\n",
       "      <td>38</td>\n",
       "      <td>2022-03-08</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>72.0</td>\n",
       "      <td>High</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   url  \\\n",
       "0    https://www.tripadvisor.ca/ShowUserReviews-g18...   \n",
       "1    https://www.tripadvisor.ca/ShowUserReviews-g18...   \n",
       "2    https://www.tripadvisor.ca/ShowUserReviews-g18...   \n",
       "3    https://www.tripadvisor.ca/ShowUserReviews-g22...   \n",
       "4    https://www.tripadvisor.ca/ShowUserReviews-g18...   \n",
       "..                                                 ...   \n",
       "995  https://www.tripadvisor.ca/ShowUserReviews-g22...   \n",
       "996  https://www.tripadvisor.ca/ShowUserReviews-g18...   \n",
       "997  https://www.tripadvisor.ca/ShowUserReviews-g22...   \n",
       "998  https://www.tripadvisor.ca/ShowUserReviews-g18...   \n",
       "999  https://www.tripadvisor.ca/ShowUserReviews-g18...   \n",
       "\n",
       "                                       hotel_name  \\\n",
       "0                              Novotel Maastricht   \n",
       "1                       citizenM Schiphol Airport   \n",
       "2                       citizenM Schiphol Airport   \n",
       "3                   Ibis Budget Amsterdam Airport   \n",
       "4                    Bastion Hotel Rotterdam Zuid   \n",
       "..                                            ...   \n",
       "995  Hampton by Hilton Amsterdam Airport Schiphol   \n",
       "996           Holiday Inn Eindhoven, an IHG hotel   \n",
       "997               ibis Schiphol Amsterdam Airport   \n",
       "998                     citizenM Schiphol Airport   \n",
       "999                               Room Mate Bruno   \n",
       "\n",
       "                                       review_title  \\\n",
       "0    A cut above the usual - well worth considering   \n",
       "1                                fabulous fun funky   \n",
       "2                        Great Concept - awful food   \n",
       "3                                Clean budget hotel   \n",
       "4                           Please book else where    \n",
       "..                                              ...   \n",
       "995                                      Good deal!   \n",
       "996                         Not as good as expected   \n",
       "997       Handy for the airport but a little pricey   \n",
       "998               Thank you for making things eaier   \n",
       "999                      Beyond the expectations    \n",
       "\n",
       "                                           review_text  helpful_count  \\\n",
       "0    Stayed here for five nights in mid February. T...              5   \n",
       "1    Loved this place. great value.  Rooms very sma...              0   \n",
       "2    This is a great hotel with a fantastic concept...              5   \n",
       "3    We stayed for two nights in April 2017.  There...              9   \n",
       "4    Where to start?,We tried to check in one day l...              0   \n",
       "..                                                 ...            ...   \n",
       "995  The hotel is far from what you would expect fr...              5   \n",
       "996  My review is based on the comparison to other ...              0   \n",
       "997  This is a very large Ibis.  I paid 129 which ...              0   \n",
       "998  I arrived with a booking that (unknown to me) ...              0   \n",
       "999  Two days of business offsite were successful m...             38   \n",
       "\n",
       "    publish_date  date_today  days_published quality label  \n",
       "0     2007-02-18  2022-05-19          5569.0    High  High  \n",
       "1     2011-08-11  2022-05-19          3934.0     Low   Low  \n",
       "2     2008-11-26  2022-05-19          4922.0    High  High  \n",
       "3     2017-05-24  2022-05-19          1821.0    High  High  \n",
       "4     2017-05-29  2022-05-19          1816.0     Low   Low  \n",
       "..           ...         ...             ...     ...   ...  \n",
       "995   2016-07-25  2022-05-19          2124.0    High  High  \n",
       "996   2017-11-25  2022-05-19          1636.0     Low   Low  \n",
       "997   2009-05-02  2022-05-19          4765.0     Low   Low  \n",
       "998   2016-08-24  2022-05-19          2094.0     Low   Low  \n",
       "999   2022-03-08  2022-05-19            72.0    High  High  \n",
       "\n",
       "[1000 rows x 10 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_lab = pd.read_csv(\"./ganbert/data/test_clasc.csv\")\n",
    "df_unlab = pd.read_csv(\"./ganbert/data/unlabeled_ta4607.csv\")\n",
    "df_test = pd.read_csv(\"./ganbert/data/labeled_clasc.csv\")\n",
    "\n",
    "#only if sentiment\n",
    "#indexNames = df_lab[~(df_lab['pos_neg'] == ':POS')].index \n",
    "#df_lab.drop(indexNames , inplace=True)\n",
    "#indexNames = df_test[~(df_test['pos_neg'] == ':POS')].index \n",
    "#df_test.drop(indexNames , inplace=True)\n",
    "\n",
    "df_lab['label'] = df_lab['quality']\n",
    "df_unlab['label'] = df_unlab['quality']\n",
    "df_test['label'] = df_test['quality']\n",
    "\n",
    "#df_lab = df_lab.sample(n=100)\n",
    "#df_unlab = df_unlab.sample(n=4000)\n",
    "#df_test = df_test.sample(n=500)\n",
    "\n",
    "df_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     956.000000\n",
       "mean     3166.166318\n",
       "std      1670.611772\n",
       "min       816.000000\n",
       "25%      1880.500000\n",
       "50%      2623.000000\n",
       "75%      3948.000000\n",
       "max      7112.000000\n",
       "Name: days_published, dtype: float64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove olk\n",
    "df_lab = df_lab[df_lab['days_published'] > 730] #unkown labelled are recently published because not a lot of time to acquire upvotes\n",
    "df_test = df_test[df_test['days_published'] > 730]\n",
    "\n",
    "df_lab['days_published'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['High' 'Low']\n",
      "['UNK']\n",
      "['High' 'Low']\n"
     ]
    }
   ],
   "source": [
    "#check for label list\n",
    "print(df_lab.label.unique())\n",
    "print(df_unlab.label.unique())\n",
    "print(df_test.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "High    495\n",
       "Low     461\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lab['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add labels\n",
    "label_list = ['UNK','High', 'Low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "High    495\n",
       "Low     461\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lab['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "High    99\n",
       "Low     94\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(956, 10)\n",
      "(4607, 3)\n",
      "(193, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df_lab.shape)\n",
    "print(df_unlab.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
      "            ...\n",
      "            988, 989, 991, 992, 993, 994, 995, 996, 997, 998],\n",
      "           dtype='int64', length=956)\n"
     ]
    }
   ],
   "source": [
    "print(df_lab.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to format the dataset to be used in the dataloader\n",
    "def get_examples(df):\n",
    "\n",
    "    examples = []\n",
    "\n",
    "    # iterate through each row\n",
    "    for index, row in df.iterrows():\n",
    "        examples.append((row['review_text'], row['label']))\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_examples = get_examples(df_lab)\n",
    "unlabeled_examples = get_examples(df_unlab)\n",
    "test_examples = get_examples(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6Q5jzVioTHb"
   },
   "source": [
    "Load the Tranformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $XRT_TPU_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "22cde8fbae4e49af993e33f3f2d9a28e",
      "2c671428c4df4355a7a53c71e9bd14ee",
      "44660941ffcc44beae72a1974d458583",
      "afdbd837001c4c74b5ac332ca061ef3a",
      "b489404bf53b4fab9bdb1c0c79a33008",
      "2bfb43b9e8604cbf8ebfd162267f1b8a",
      "4f556917850542da8508f9f839cae9bc",
      "28f045edfa48462fa96a94cffd3b143f",
      "14a6abbb244b41f89626a37640c63118",
      "0dccd0ab28c34880be92b35aa05e6ffb",
      "bf127a02cf6647aba4035c5cbfadc378",
      "098f203f1209452a9d4192af92da7057",
      "ec76cfd2d1da498e9b66885ff1be46b3",
      "b94243bfea7e4441b809b38c7cecd875",
      "0097aa33393342cd99be3dcc30edc5a0",
      "293c4d8660f546f79b43e0dc63250c2f",
      "9fc9479d78e442db91360de7f45b6d7f",
      "14bf2ab82bfc45bd8a3b93f2ab9aa656",
      "a56008dc6c6b41c3850611cc15fb6ea8",
      "504e8c3a107e4e04b51df39e1b3c584e",
      "1f25240f5457445795af70e20e5903f9",
      "5110d1cb9a7547f49244113dc5dd8321",
      "d3a13b7869354881ac7b7887e05d56a7",
      "4d22913664fb4cdbb38e217d4197601d",
      "870fe8f58bb24a47b6a98fa0eed0ebf5",
      "193a5a054d6f4a319842820c4c308322",
      "5a478b81997c4263a60d938447232fd9",
      "5fbebd67d40e470e8a75a4b5b540bbdf",
      "d8b619dff35e4f8cabf586221ad8c962",
      "d7bef2816920414f99a5c9cc676ec254",
      "b465cf9004f549ffa85444bfa16ee4c2",
      "748d5c1fb00e4d91809003527319a9f6",
      "7d501eb3d36e48128a5232879141b281",
      "547d7329b8554b7bb8ae51d61a5e41f8",
      "81b6bafd3fc248afa76cf463f2cb8ab8",
      "bac8f28c84144450b24bbc97fa4860db",
      "30e0829529874db1802f411f72f3d76a",
      "83dd72fbb4204fefb951b3800d73a8d2",
      "f9390d4fc9b147729f1ef5ea85d03774",
      "ddf20490dc874352aa7df35f07a60bcc",
      "c0f0d9a0d4f4440e81e5a6d5a2a3b4ab",
      "f41b83ccf26c40ed88ca6eaf49e09de5",
      "be6339f6256d4b579c53ef8b430ecb25",
      "b79fef6d585843c0a4d885edb2d01ebd"
     ]
    },
    "id": "gxghkkZq3Gbn",
    "outputId": "a4a5afd0-1b6c-4c2d-e3eb-7ced49df4e33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "transformer = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rd_ixn5qn_zV"
   },
   "source": [
    "Function required to load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "W7cP8q7K3BId"
   },
   "outputs": [],
   "source": [
    "#not needed to run\n",
    "#def get_qc_examples(input_file):\n",
    "#  \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "#  examples = []\n",
    "#\n",
    "#  with open(input_file, 'r') as f:\n",
    "#      contents = f.read()\n",
    "#      file_as_list = contents.splitlines()\n",
    "#      for line in file_as_list[1:]:\n",
    "#          split = line.split(\" \")\n",
    "#          question = ' '.join(split[1:])\n",
    "#\n",
    "#          text_a = question\n",
    "#          inn_split = split[0].split(\":\")\n",
    "#          label = inn_split[0] + \"_\" + inn_split[1]\n",
    "#          examples.append((text_a, label))\n",
    "#      f.close()\n",
    "#\n",
    "#  return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K43tOavNqib4"
   },
   "source": [
    "**Load** the input QC dataset (fine-grained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "cXCwFyF2qhw7"
   },
   "outputs": [],
   "source": [
    "#not needed to run\n",
    "#Load the examples\n",
    "#labeled_examples = get_qc_examples(labeled_file)\n",
    "#unlabeled_examples = get_qc_examples(unlabeled_file)\n",
    "#test_examples = get_qc_examples(test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBhaW5vBfR6B"
   },
   "source": [
    "Functions required to convert examples into Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "id": "fmKL5AD7I4Zg"
   },
   "outputs": [],
   "source": [
    "def generate_data_loader(input_examples, label_masks, label_map, do_shuffle = False, balance_label_examples = False):\n",
    "  '''\n",
    "  Generate a Dataloader given the input examples, eventually masked if they are \n",
    "  to be considered NOT labeled.\n",
    "  '''\n",
    "  examples = []\n",
    "\n",
    "  # Count the percentage of labeled examples  \n",
    "  num_labeled_examples = 0\n",
    "  for label_mask in label_masks:\n",
    "    if label_mask: \n",
    "      num_labeled_examples += 1\n",
    "  label_mask_rate = num_labeled_examples/len(input_examples)\n",
    "\n",
    "  # if required it applies the balance\n",
    "  for index, ex in enumerate(input_examples): \n",
    "    if label_mask_rate == 1 or not balance_label_examples:\n",
    "      examples.append((ex, label_masks[index]))\n",
    "    else:\n",
    "      # IT SIMULATE A LABELED EXAMPLE\n",
    "      if label_masks[index]:\n",
    "        balance = int(1/label_mask_rate)\n",
    "        balance = int(math.log(balance,2))\n",
    "        if balance < 1:\n",
    "          balance = 1\n",
    "        for b in range(0, int(balance)):\n",
    "          examples.append((ex, label_masks[index]))\n",
    "      else:\n",
    "        examples.append((ex, label_masks[index]))\n",
    "  \n",
    "  #-----------------------------------------------\n",
    "  # Generate input examples to the Transformer\n",
    "  #-----------------------------------------------\n",
    "  input_ids = []\n",
    "  input_mask_array = []\n",
    "  label_mask_array = []\n",
    "  label_id_array = []\n",
    "\n",
    "  # Tokenization \n",
    "  for (text, label_mask) in examples:\n",
    "    encoded_sent = tokenizer.encode(text[0], add_special_tokens=True, max_length=max_seq_length, padding=\"max_length\", truncation=True)\n",
    "    input_ids.append(encoded_sent)\n",
    "    label_id_array.append(label_map[text[1]])\n",
    "    label_mask_array.append(label_mask)\n",
    "  \n",
    "  # Attention to token (to ignore padded input wordpieces)\n",
    "  for sent in input_ids:\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]                          \n",
    "    input_mask_array.append(att_mask)\n",
    "  # Convertion to Tensor\n",
    "  input_ids = torch.tensor(input_ids) \n",
    "  input_mask_array = torch.tensor(input_mask_array)\n",
    "  label_id_array = torch.tensor(label_id_array, dtype=torch.long)\n",
    "  label_mask_array = torch.tensor(label_mask_array)\n",
    "\n",
    "  # Building the TensorDataset\n",
    "  dataset = TensorDataset(input_ids, input_mask_array, label_id_array, label_mask_array)\n",
    "\n",
    "  if do_shuffle:\n",
    "    sampler = RandomSampler\n",
    "  else:\n",
    "    sampler = SequentialSampler\n",
    "\n",
    "  # Building the DataLoader\n",
    "  return DataLoader(\n",
    "              dataset,  # The training samples.\n",
    "              sampler = sampler(dataset), \n",
    "              batch_size = batch_size) # Trains with this batch size.\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Do3O-VeefT3g"
   },
   "source": [
    "Convert the input examples into DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "4c-nsMXlKX-D"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-204-b5617700c116>:54: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  label_mask_array = torch.tensor(label_mask_array)\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow_datasets\n",
    "# import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "\n",
    "# import torch\n",
    "# import tensorflow\n",
    "# import TensorData from 'tensorfow'\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import RandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SequentialSampler\n",
    "\n",
    "label_map = {}\n",
    "for (i, label) in enumerate(label_list):\n",
    "  label_map[label] = i\n",
    "#------------------------------\n",
    "#   Load the train dataset\n",
    "#------------------------------\n",
    "train_examples = labeled_examples\n",
    "#The labeled (train) dataset is assigned with a mask set to True\n",
    "train_label_masks = np.ones(len(labeled_examples), dtype=bool)\n",
    "#If unlabel examples are available\n",
    "if unlabeled_examples:\n",
    "  train_examples = train_examples + unlabeled_examples\n",
    "  #The unlabeled (train) dataset is assigned with a mask set to False\n",
    "  tmp_masks = np.zeros(len(unlabeled_examples), dtype=bool)\n",
    "  train_label_masks = np.concatenate([train_label_masks,tmp_masks])\n",
    "\n",
    "train_dataloader = generate_data_loader(train_examples, train_label_masks, label_map, do_shuffle = True, balance_label_examples = apply_balance)\n",
    "\n",
    "#------------------------------\n",
    "#   Load the test dataset\n",
    "#------------------------------\n",
    "#The labeled (test) dataset is assigned with a mask set to True\n",
    "test_label_masks = np.ones(len(test_examples), dtype=bool)\n",
    "\n",
    "test_dataloader = generate_data_loader(test_examples, test_label_masks, label_map, do_shuffle = False, balance_label_examples = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ihcw3vquaQm"
   },
   "source": [
    "We define the Generator and Discriminator as discussed in https://www.aclweb.org/anthology/2020.acl-main.191/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "18kY64-n3I6y"
   },
   "outputs": [],
   "source": [
    "#------------------------------\n",
    "#   The Generator as in \n",
    "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
    "#   https://github.com/crux82/ganbert\n",
    "#------------------------------\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_size=100, output_size=512, hidden_sizes=[512], dropout_rate=0.1):\n",
    "        super(Generator, self).__init__()\n",
    "        layers = []\n",
    "        hidden_sizes = [noise_size] + hidden_sizes\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
    "\n",
    "        layers.append(nn.Linear(hidden_sizes[-1],output_size))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, noise):\n",
    "        output_rep = self.layers(noise)\n",
    "        return output_rep\n",
    "\n",
    "#------------------------------\n",
    "#   The Discriminator\n",
    "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
    "#   https://github.com/crux82/ganbert\n",
    "#------------------------------\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size=512, hidden_sizes=[512], num_labels=2, dropout_rate=0.1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_dropout = nn.Dropout(p=dropout_rate)\n",
    "        layers = []\n",
    "        hidden_sizes = [input_size] + hidden_sizes\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
    "\n",
    "        self.layers = nn.Sequential(*layers) #per il flatten\n",
    "        self.logit = nn.Linear(hidden_sizes[-1],num_labels+1) # +1 for the probability of this sample being fake/real.\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input_rep):\n",
    "        input_rep = self.input_dropout(input_rep)\n",
    "        last_rep = self.layers(input_rep)\n",
    "        logits = self.logit(last_rep)\n",
    "        probs = self.softmax(logits)\n",
    "        return last_rep, logits, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uje9s2zQunFc"
   },
   "source": [
    "We instantiate the Discriminator and Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "Ylz5rvqE3U2S"
   },
   "outputs": [],
   "source": [
    "# The config file is required to get the dimension of the vector produced by \n",
    "# the underlying transformer\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "hidden_size = int(config.hidden_size)\n",
    "# Define the number and width of hidden layers\n",
    "hidden_levels_g = [hidden_size for i in range(0, num_hidden_layers_g)]\n",
    "hidden_levels_d = [hidden_size for i in range(0, num_hidden_layers_d)]\n",
    "\n",
    "#-------------------------------------------------\n",
    "#   Instantiate the Generator and Discriminator\n",
    "#-------------------------------------------------\n",
    "generator = Generator(noise_size=noise_size, output_size=hidden_size, hidden_sizes=hidden_levels_g, dropout_rate=out_dropout_rate)\n",
    "discriminator = Discriminator(input_size=hidden_size, hidden_sizes=hidden_levels_d, num_labels=len(label_list), dropout_rate=out_dropout_rate)\n",
    "\n",
    "# Put everything in the GPU if available\n",
    "if torch.cuda.is_available():    \n",
    "  generator.cuda()\n",
    "  discriminator.cuda()\n",
    "  transformer.cuda()\n",
    "  if multi_gpu:\n",
    "    transformer = torch.nn.DataParallel(transformer)\n",
    "\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VG3qzp2-usZE"
   },
   "source": [
    "Let's go with the training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NhqylHGK3Va4",
    "outputId": "726efd06-d8de-4a45-a7bb-f186994a6b2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of    102.    Elapsed: 0:00:56.\n",
      "  Batch    20  of    102.    Elapsed: 0:01:36.\n",
      "  Batch    30  of    102.    Elapsed: 0:02:19.\n",
      "  Batch    40  of    102.    Elapsed: 0:03:02.\n",
      "  Batch    50  of    102.    Elapsed: 0:03:45.\n",
      "  Batch    60  of    102.    Elapsed: 0:04:28.\n",
      "  Batch    70  of    102.    Elapsed: 0:05:11.\n",
      "  Batch    80  of    102.    Elapsed: 0:05:51.\n",
      "  Batch    90  of    102.    Elapsed: 0:06:32.\n",
      "  Batch   100  of    102.    Elapsed: 0:07:14.\n",
      "\n",
      "  Average training loss generetor: 0.713\n",
      "  Average training loss discriminator: 1.430\n",
      "  Training epcoh took: 0:07:21\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.720\n",
      "  Test Loss: 0.710\n",
      "  Test took: 0:00:02\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of    102.    Elapsed: 0:00:46.\n",
      "  Batch    20  of    102.    Elapsed: 0:01:29.\n",
      "  Batch    30  of    102.    Elapsed: 0:02:13.\n",
      "  Batch    40  of    102.    Elapsed: 0:02:54.\n",
      "  Batch    50  of    102.    Elapsed: 0:03:39.\n",
      "  Batch    60  of    102.    Elapsed: 0:04:22.\n",
      "  Batch    70  of    102.    Elapsed: 0:05:05.\n",
      "  Batch    80  of    102.    Elapsed: 0:05:50.\n",
      "  Batch    90  of    102.    Elapsed: 0:06:33.\n",
      "  Batch   100  of    102.    Elapsed: 0:07:17.\n",
      "\n",
      "  Average training loss generetor: 0.718\n",
      "  Average training loss discriminator: 1.060\n",
      "  Training epcoh took: 0:07:24\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.689\n",
      "  Test Loss: 1.073\n",
      "  Test took: 0:00:02\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of    102.    Elapsed: 0:00:42.\n",
      "  Batch    20  of    102.    Elapsed: 0:01:26.\n",
      "  Batch    30  of    102.    Elapsed: 0:02:10.\n",
      "  Batch    40  of    102.    Elapsed: 0:02:53.\n",
      "  Batch    50  of    102.    Elapsed: 0:03:34.\n",
      "  Batch    60  of    102.    Elapsed: 0:04:17.\n",
      "  Batch    70  of    102.    Elapsed: 0:05:00.\n",
      "  Batch    80  of    102.    Elapsed: 0:05:42.\n",
      "  Batch    90  of    102.    Elapsed: 0:06:23.\n",
      "  Batch   100  of    102.    Elapsed: 0:07:07.\n",
      "\n",
      "  Average training loss generetor: 0.710\n",
      "  Average training loss discriminator: 0.821\n",
      "  Training epcoh took: 0:07:18\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.642\n",
      "  Test Loss: 2.228\n",
      "  Test took: 0:00:02\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of    102.    Elapsed: 0:00:43.\n",
      "  Batch    20  of    102.    Elapsed: 0:01:25.\n",
      "  Batch    30  of    102.    Elapsed: 0:02:05.\n",
      "  Batch    40  of    102.    Elapsed: 0:02:46.\n",
      "  Batch    50  of    102.    Elapsed: 0:03:29.\n",
      "  Batch    60  of    102.    Elapsed: 0:04:09.\n",
      "  Batch    70  of    102.    Elapsed: 0:04:50.\n",
      "  Batch    80  of    102.    Elapsed: 0:05:34.\n",
      "  Batch    90  of    102.    Elapsed: 0:06:14.\n",
      "  Batch   100  of    102.    Elapsed: 0:06:53.\n",
      "\n",
      "  Average training loss generetor: 0.707\n",
      "  Average training loss discriminator: 0.776\n",
      "  Training epcoh took: 0:07:02\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.741\n",
      "  Test Loss: 2.549\n",
      "  Test took: 0:00:02\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of    102.    Elapsed: 0:00:42.\n",
      "  Batch    20  of    102.    Elapsed: 0:01:25.\n",
      "  Batch    30  of    102.    Elapsed: 0:02:07.\n",
      "  Batch    40  of    102.    Elapsed: 0:02:49.\n",
      "  Batch    50  of    102.    Elapsed: 0:03:30.\n",
      "  Batch    60  of    102.    Elapsed: 0:04:13.\n",
      "  Batch    70  of    102.    Elapsed: 0:04:56.\n",
      "  Batch    80  of    102.    Elapsed: 0:05:38.\n",
      "  Batch    90  of    102.    Elapsed: 0:06:20.\n",
      "  Batch   100  of    102.    Elapsed: 0:07:01.\n",
      "\n",
      "  Average training loss generetor: 0.707\n",
      "  Average training loss discriminator: 0.775\n",
      "  Training epcoh took: 0:07:08\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.720\n",
      "  Test Loss: 1.773\n",
      "  Test took: 0:00:02\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of    102.    Elapsed: 0:00:40.\n",
      "  Batch    20  of    102.    Elapsed: 0:01:20.\n",
      "  Batch    30  of    102.    Elapsed: 0:02:04.\n",
      "  Batch    40  of    102.    Elapsed: 0:02:45.\n",
      "  Batch    50  of    102.    Elapsed: 0:03:25.\n",
      "  Batch    60  of    102.    Elapsed: 0:04:04.\n",
      "  Batch    70  of    102.    Elapsed: 0:04:45.\n",
      "  Batch    80  of    102.    Elapsed: 0:05:30.\n",
      "  Batch    90  of    102.    Elapsed: 0:06:11.\n",
      "  Batch   100  of    102.    Elapsed: 0:06:50.\n",
      "\n",
      "  Average training loss generetor: 0.704\n",
      "  Average training loss discriminator: 0.755\n",
      "  Training epcoh took: 0:06:59\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.725\n",
      "  Test Loss: 2.810\n",
      "  Test took: 0:00:02\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of    102.    Elapsed: 0:00:42.\n",
      "  Batch    20  of    102.    Elapsed: 0:01:22.\n",
      "  Batch    30  of    102.    Elapsed: 0:02:05.\n",
      "  Batch    40  of    102.    Elapsed: 0:02:46.\n",
      "  Batch    50  of    102.    Elapsed: 0:03:29.\n",
      "  Batch    60  of    102.    Elapsed: 0:04:13.\n",
      "  Batch    70  of    102.    Elapsed: 0:04:55.\n",
      "  Batch    80  of    102.    Elapsed: 0:05:41.\n",
      "  Batch    90  of    102.    Elapsed: 0:06:23.\n",
      "  Batch   100  of    102.    Elapsed: 0:07:06.\n",
      "\n",
      "  Average training loss generetor: 0.703\n",
      "  Average training loss discriminator: 0.738\n",
      "  Training epcoh took: 0:07:15\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.751\n",
      "  Test Loss: 1.783\n",
      "  Test took: 0:00:02\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of    102.    Elapsed: 0:00:42.\n",
      "  Batch    20  of    102.    Elapsed: 0:01:26.\n",
      "  Batch    30  of    102.    Elapsed: 0:02:10.\n",
      "  Batch    40  of    102.    Elapsed: 0:02:50.\n",
      "  Batch    50  of    102.    Elapsed: 0:03:35.\n",
      "  Batch    60  of    102.    Elapsed: 0:04:19.\n",
      "  Batch    70  of    102.    Elapsed: 0:05:00.\n",
      "  Batch    80  of    102.    Elapsed: 0:05:42.\n",
      "  Batch    90  of    102.    Elapsed: 0:06:22.\n",
      "  Batch   100  of    102.    Elapsed: 0:07:02.\n",
      "\n",
      "  Average training loss generetor: 0.703\n",
      "  Average training loss discriminator: 0.737\n",
      "  Training epcoh took: 0:07:09\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.658\n",
      "  Test Loss: 1.523\n",
      "  Test took: 0:00:02\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of    102.    Elapsed: 0:00:43.\n",
      "  Batch    20  of    102.    Elapsed: 0:01:26.\n",
      "  Batch    30  of    102.    Elapsed: 0:02:09.\n",
      "  Batch    40  of    102.    Elapsed: 0:02:49.\n",
      "  Batch    50  of    102.    Elapsed: 0:03:30.\n",
      "  Batch    60  of    102.    Elapsed: 0:04:13.\n",
      "  Batch    70  of    102.    Elapsed: 0:04:54.\n",
      "  Batch    80  of    102.    Elapsed: 0:05:34.\n",
      "  Batch    90  of    102.    Elapsed: 0:06:16.\n",
      "  Batch   100  of    102.    Elapsed: 0:06:58.\n",
      "\n",
      "  Average training loss generetor: 0.704\n",
      "  Average training loss discriminator: 0.744\n",
      "  Training epcoh took: 0:07:05\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.694\n",
      "  Test Loss: 3.148\n",
      "  Test took: 0:00:02\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of    102.    Elapsed: 0:00:41.\n",
      "  Batch    20  of    102.    Elapsed: 0:01:25.\n",
      "  Batch    30  of    102.    Elapsed: 0:02:07.\n",
      "  Batch    40  of    102.    Elapsed: 0:02:48.\n",
      "  Batch    50  of    102.    Elapsed: 0:03:30.\n",
      "  Batch    60  of    102.    Elapsed: 0:04:11.\n",
      "  Batch    70  of    102.    Elapsed: 0:04:53.\n",
      "  Batch    80  of    102.    Elapsed: 0:05:35.\n",
      "  Batch    90  of    102.    Elapsed: 0:06:18.\n",
      "  Batch   100  of    102.    Elapsed: 0:06:58.\n",
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.734\n",
      "  Training epcoh took: 0:07:06\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.725\n",
      "  Test Loss: 2.286\n",
      "  Test took: 0:00:02\n"
     ]
    }
   ],
   "source": [
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "#models parameters\n",
    "transformer_vars = [i for i in transformer.parameters()]\n",
    "d_vars = transformer_vars + [v for v in discriminator.parameters()]\n",
    "g_vars = [v for v in generator.parameters()]\n",
    "\n",
    "#optimizer\n",
    "dis_optimizer = torch.optim.AdamW(d_vars, lr=learning_rate_discriminator)\n",
    "gen_optimizer = torch.optim.AdamW(g_vars, lr=learning_rate_generator) \n",
    "\n",
    "#scheduler\n",
    "if apply_scheduler:\n",
    "  num_train_examples = len(train_examples)\n",
    "  num_train_steps = int(num_train_examples / batch_size * num_train_epochs)\n",
    "  num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
    "\n",
    "  scheduler_d = get_constant_schedule_with_warmup(dis_optimizer, \n",
    "                                           num_warmup_steps = num_warmup_steps)\n",
    "  scheduler_g = get_constant_schedule_with_warmup(gen_optimizer, \n",
    "                                           num_warmup_steps = num_warmup_steps)\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, num_train_epochs):\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, num_train_epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    tr_g_loss = 0\n",
    "    tr_d_loss = 0\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    transformer.train() \n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every print_each_n_step batches.\n",
    "        if step % print_each_n_step == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        b_label_mask = batch[3].to(device)\n",
    "\n",
    "        real_batch_size = b_input_ids.shape[0]\n",
    "     \n",
    "        # Encode real data in the Transformer\n",
    "        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "        hidden_states = model_outputs[-1]\n",
    "        \n",
    "        # Generate fake data that should have the same distribution of the ones\n",
    "        # encoded by the transformer. \n",
    "        # First noisy input are used in input to the Generator\n",
    "        noise = torch.zeros(real_batch_size, noise_size, device=device).uniform_(0, 1)\n",
    "        # Gnerate Fake data\n",
    "        gen_rep = generator(noise)\n",
    "\n",
    "        # Generate the output of the Discriminator for real and fake data.\n",
    "        # First, we put together the output of the tranformer and the generator\n",
    "        disciminator_input = torch.cat([hidden_states, gen_rep], dim=0)\n",
    "        # Then, we select the output of the disciminator\n",
    "        features, logits, probs = discriminator(disciminator_input)\n",
    "\n",
    "        # Finally, we separate the discriminator's output for the real and fake\n",
    "        # data\n",
    "        features_list = torch.split(features, real_batch_size)\n",
    "        D_real_features = features_list[0]\n",
    "        D_fake_features = features_list[1]\n",
    "      \n",
    "        logits_list = torch.split(logits, real_batch_size)\n",
    "        D_real_logits = logits_list[0]\n",
    "        D_fake_logits = logits_list[1]\n",
    "        \n",
    "        probs_list = torch.split(probs, real_batch_size)\n",
    "        D_real_probs = probs_list[0]\n",
    "        D_fake_probs = probs_list[1]\n",
    "\n",
    "        #---------------------------------\n",
    "        #  LOSS evaluation\n",
    "        #---------------------------------\n",
    "        # Generator's LOSS estimation\n",
    "        g_loss_d = -1 * torch.mean(torch.log(1 - D_fake_probs[:,-1] + epsilon))\n",
    "        g_feat_reg = torch.mean(torch.pow(torch.mean(D_real_features, dim=0) - torch.mean(D_fake_features, dim=0), 2))\n",
    "        g_loss = g_loss_d + g_feat_reg\n",
    "  \n",
    "        # Disciminator's LOSS estimation\n",
    "        logits = D_real_logits[:,0:-1]\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        # The discriminator provides an output for labeled and unlabeled real data\n",
    "        # so the loss evaluated for unlabeled data is ignored (masked)\n",
    "        label2one_hot = torch.nn.functional.one_hot(b_labels, len(label_list))\n",
    "        per_example_loss = -torch.sum(label2one_hot * log_probs, dim=-1)\n",
    "        per_example_loss = torch.masked_select(per_example_loss, b_label_mask.to(device))\n",
    "        labeled_example_count = per_example_loss.type(torch.float32).numel()\n",
    "\n",
    "        # It may be the case that a batch does not contain labeled examples, \n",
    "        # so the \"supervised loss\" in this case is not evaluated\n",
    "        if labeled_example_count == 0:\n",
    "          D_L_Supervised = 0\n",
    "        else:\n",
    "          D_L_Supervised = torch.div(torch.sum(per_example_loss.to(device)), labeled_example_count)\n",
    "                 \n",
    "        D_L_unsupervised1U = -1 * torch.mean(torch.log(1 - D_real_probs[:, -1] + epsilon))\n",
    "        D_L_unsupervised2U = -1 * torch.mean(torch.log(D_fake_probs[:, -1] + epsilon))\n",
    "        d_loss = D_L_Supervised + D_L_unsupervised1U + D_L_unsupervised2U\n",
    "\n",
    "        #---------------------------------\n",
    "        #  OPTIMIZATION\n",
    "        #---------------------------------\n",
    "        # Avoid gradient accumulation\n",
    "        gen_optimizer.zero_grad()\n",
    "        dis_optimizer.zero_grad()\n",
    "\n",
    "        # Calculate weigth updates\n",
    "        # retain_graph=True is required since the underlying graph will be deleted after backward\n",
    "        g_loss.backward(retain_graph=True)\n",
    "        d_loss.backward() \n",
    "        \n",
    "        # Apply modifications\n",
    "        gen_optimizer.step()\n",
    "        dis_optimizer.step()\n",
    "\n",
    "        # A detail log of the individual losses\n",
    "        #print(\"{0:.4f}\\t{1:.4f}\\t{2:.4f}\\t{3:.4f}\\t{4:.4f}\".\n",
    "        #      format(D_L_Supervised, D_L_unsupervised1U, D_L_unsupervised2U,\n",
    "        #             g_loss_d, g_feat_reg))\n",
    "\n",
    "        # Save the losses to print them later\n",
    "        tr_g_loss += g_loss.item()\n",
    "        tr_d_loss += d_loss.item()\n",
    "\n",
    "        # Update the learning rate with the scheduler\n",
    "        if apply_scheduler:\n",
    "          scheduler_d.step()\n",
    "          scheduler_g.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss_g = tr_g_loss / len(train_dataloader)\n",
    "    avg_train_loss_d = tr_d_loss / len(train_dataloader)             \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss generetor: {0:.3f}\".format(avg_train_loss_g))\n",
    "    print(\"  Average training loss discriminator: {0:.3f}\".format(avg_train_loss_d))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #     TEST ON THE EVALUATION DATASET\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our test set.\n",
    "    print(\"\")\n",
    "    print(\"Running Test...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    transformer.eval() #maybe redundant\n",
    "    discriminator.eval()\n",
    "    generator.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_test_accuracy = 0\n",
    "   \n",
    "    total_test_loss = 0\n",
    "    nb_test_steps = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels_ids = []\n",
    "\n",
    "    #loss\n",
    "    nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
    "            hidden_states = model_outputs[-1]\n",
    "            _, logits, probs = discriminator(hidden_states)\n",
    "            ###log_probs = F.log_softmax(probs[:,1:], dim=-1)\n",
    "            filtered_logits = logits[:,0:-1]\n",
    "            # Accumulate the test loss.\n",
    "            total_test_loss += nll_loss(filtered_logits, b_labels)\n",
    "            \n",
    "        # Accumulate the predictions and the input labels\n",
    "        _, preds = torch.max(filtered_logits, 1)\n",
    "        all_preds += preds.detach().cpu()\n",
    "        all_labels_ids += b_labels.detach().cpu()\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    all_preds = torch.stack(all_preds).numpy()\n",
    "    all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
    "    test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
    "    print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "    avg_test_loss = avg_test_loss.item()\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    test_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n",
    "    print(\"  Test took: {:}\".format(test_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss generator': avg_train_loss_g,\n",
    "            'Training Loss discriminator': avg_train_loss_d,\n",
    "            'Valid. Loss': avg_test_loss,\n",
    "            'Valid. Accur.': test_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Test Time': test_time\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDm9NProRB4c",
    "outputId": "2ffebcf1-6b39-4442-88c6-5f72a58a3722"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1, 'Training Loss generator': 0.7130512770484475, 'Training Loss discriminator': 1.430281353931801, 'Valid. Loss': 0.7095646858215332, 'Valid. Accur.': 0.7202072538860104, 'Training Time': '0:07:21', 'Test Time': '0:00:02'}\n",
      "{'epoch': 2, 'Training Loss generator': 0.7184293515541974, 'Training Loss discriminator': 1.060186362734028, 'Valid. Loss': 1.0732154846191406, 'Valid. Accur.': 0.689119170984456, 'Training Time': '0:07:24', 'Test Time': '0:00:02'}\n",
      "{'epoch': 3, 'Training Loss generator': 0.7101268540410435, 'Training Loss discriminator': 0.8206774820299709, 'Valid. Loss': 2.2275450229644775, 'Valid. Accur.': 0.6424870466321243, 'Training Time': '0:07:18', 'Test Time': '0:00:02'}\n",
      "{'epoch': 4, 'Training Loss generator': 0.7074617667525422, 'Training Loss discriminator': 0.7764657776729733, 'Valid. Loss': 2.5491764545440674, 'Valid. Accur.': 0.7409326424870466, 'Training Time': '0:07:02', 'Test Time': '0:00:02'}\n",
      "{'epoch': 5, 'Training Loss generator': 0.7071660459041595, 'Training Loss discriminator': 0.7748078055241528, 'Valid. Loss': 1.7730902433395386, 'Valid. Accur.': 0.7202072538860104, 'Training Time': '0:07:08', 'Test Time': '0:00:02'}\n",
      "{'epoch': 6, 'Training Loss generator': 0.7044076685811959, 'Training Loss discriminator': 0.7546887444514855, 'Valid. Loss': 2.809511184692383, 'Valid. Accur.': 0.7253886010362695, 'Training Time': '0:06:59', 'Test Time': '0:00:02'}\n",
      "{'epoch': 7, 'Training Loss generator': 0.7033789414985507, 'Training Loss discriminator': 0.7375296424416935, 'Valid. Loss': 1.782901644706726, 'Valid. Accur.': 0.7512953367875648, 'Training Time': '0:07:15', 'Test Time': '0:00:02'}\n",
      "{'epoch': 8, 'Training Loss generator': 0.7028095809852376, 'Training Loss discriminator': 0.7366223370327669, 'Valid. Loss': 1.5231060981750488, 'Valid. Accur.': 0.6580310880829016, 'Training Time': '0:07:09', 'Test Time': '0:00:02'}\n",
      "{'epoch': 9, 'Training Loss generator': 0.7037053908787522, 'Training Loss discriminator': 0.744308087755652, 'Valid. Loss': 3.147613525390625, 'Valid. Accur.': 0.694300518134715, 'Training Time': '0:07:05', 'Test Time': '0:00:02'}\n",
      "{'epoch': 10, 'Training Loss generator': 0.7008834078031427, 'Training Loss discriminator': 0.7338831944792878, 'Valid. Loss': 2.2862367630004883, 'Valid. Accur.': 0.7253886010362695, 'Training Time': '0:07:06', 'Test Time': '0:00:02'}\n",
      "\n",
      "Training complete!\n",
      "Total training took 1:12:03 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "for stat in training_stats:\n",
    "  print(stat)\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.81      0.75        99\n",
      "           2       0.76      0.64      0.69        94\n",
      "\n",
      "    accuracy                           0.73       193\n",
      "   macro avg       0.73      0.72      0.72       193\n",
      "weighted avg       0.73      0.73      0.72       193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(all_labels_ids, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(all_labels_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1 1 2 1 2 2 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 2 2 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 2 2 2 2 2 2 2\n",
      " 2 1 1 2 1 2 2 2 2 2 2 2 1 2 1 2 1 1 2 1 2 2 2 1 1 2 2 2 1 1 2 1 2 2 2 2 2\n",
      " 1 2 1 1 2 2 1 2 2 1 2 1 1 2 1 1 1 2 2 2 2 2 1 1 2 1 2 2 1 1 1 2 1 2 2 1 2\n",
      " 2 2 2 2 2 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "GANBERT_pytorch croce.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0097aa33393342cd99be3dcc30edc5a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_504e8c3a107e4e04b51df39e1b3c584e",
      "max": 435779157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a56008dc6c6b41c3850611cc15fb6ea8",
      "value": 435779157
     }
    },
    "098f203f1209452a9d4192af92da7057": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b94243bfea7e4441b809b38c7cecd875",
       "IPY_MODEL_0097aa33393342cd99be3dcc30edc5a0",
       "IPY_MODEL_293c4d8660f546f79b43e0dc63250c2f"
      ],
      "layout": "IPY_MODEL_ec76cfd2d1da498e9b66885ff1be46b3"
     }
    },
    "0dccd0ab28c34880be92b35aa05e6ffb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14a6abbb244b41f89626a37640c63118": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14bf2ab82bfc45bd8a3b93f2ab9aa656": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "193a5a054d6f4a319842820c4c308322": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b465cf9004f549ffa85444bfa16ee4c2",
      "max": 213450,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d7bef2816920414f99a5c9cc676ec254",
      "value": 213450
     }
    },
    "1f25240f5457445795af70e20e5903f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "22cde8fbae4e49af993e33f3f2d9a28e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_44660941ffcc44beae72a1974d458583",
       "IPY_MODEL_afdbd837001c4c74b5ac332ca061ef3a",
       "IPY_MODEL_b489404bf53b4fab9bdb1c0c79a33008"
      ],
      "layout": "IPY_MODEL_2c671428c4df4355a7a53c71e9bd14ee"
     }
    },
    "28f045edfa48462fa96a94cffd3b143f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "293c4d8660f546f79b43e0dc63250c2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5110d1cb9a7547f49244113dc5dd8321",
      "placeholder": "",
      "style": "IPY_MODEL_1f25240f5457445795af70e20e5903f9",
      "value": " 436M/436M [00:29&lt;00:00, 14.8MB/s]"
     }
    },
    "2bfb43b9e8604cbf8ebfd162267f1b8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c671428c4df4355a7a53c71e9bd14ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30e0829529874db1802f411f72f3d76a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f41b83ccf26c40ed88ca6eaf49e09de5",
      "max": 435797,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c0f0d9a0d4f4440e81e5a6d5a2a3b4ab",
      "value": 435797
     }
    },
    "44660941ffcc44beae72a1974d458583": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f556917850542da8508f9f839cae9bc",
      "placeholder": "",
      "style": "IPY_MODEL_2bfb43b9e8604cbf8ebfd162267f1b8a",
      "value": "Downloading: 100%"
     }
    },
    "4d22913664fb4cdbb38e217d4197601d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f556917850542da8508f9f839cae9bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "504e8c3a107e4e04b51df39e1b3c584e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5110d1cb9a7547f49244113dc5dd8321": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "547d7329b8554b7bb8ae51d61a5e41f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bac8f28c84144450b24bbc97fa4860db",
       "IPY_MODEL_30e0829529874db1802f411f72f3d76a",
       "IPY_MODEL_83dd72fbb4204fefb951b3800d73a8d2"
      ],
      "layout": "IPY_MODEL_81b6bafd3fc248afa76cf463f2cb8ab8"
     }
    },
    "5a478b81997c4263a60d938447232fd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d501eb3d36e48128a5232879141b281",
      "placeholder": "",
      "style": "IPY_MODEL_748d5c1fb00e4d91809003527319a9f6",
      "value": " 213k/213k [00:00&lt;00:00, 102kB/s]"
     }
    },
    "5fbebd67d40e470e8a75a4b5b540bbdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "748d5c1fb00e4d91809003527319a9f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d501eb3d36e48128a5232879141b281": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81b6bafd3fc248afa76cf463f2cb8ab8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83dd72fbb4204fefb951b3800d73a8d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b79fef6d585843c0a4d885edb2d01ebd",
      "placeholder": "",
      "style": "IPY_MODEL_be6339f6256d4b579c53ef8b430ecb25",
      "value": " 436k/436k [00:00&lt;00:00, 1.26MB/s]"
     }
    },
    "870fe8f58bb24a47b6a98fa0eed0ebf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8b619dff35e4f8cabf586221ad8c962",
      "placeholder": "",
      "style": "IPY_MODEL_5fbebd67d40e470e8a75a4b5b540bbdf",
      "value": "Downloading: 100%"
     }
    },
    "9fc9479d78e442db91360de7f45b6d7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a56008dc6c6b41c3850611cc15fb6ea8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "afdbd837001c4c74b5ac332ca061ef3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14a6abbb244b41f89626a37640c63118",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_28f045edfa48462fa96a94cffd3b143f",
      "value": 570
     }
    },
    "b465cf9004f549ffa85444bfa16ee4c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b489404bf53b4fab9bdb1c0c79a33008": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf127a02cf6647aba4035c5cbfadc378",
      "placeholder": "",
      "style": "IPY_MODEL_0dccd0ab28c34880be92b35aa05e6ffb",
      "value": " 570/570 [00:00&lt;00:00, 12.0kB/s]"
     }
    },
    "b79fef6d585843c0a4d885edb2d01ebd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b94243bfea7e4441b809b38c7cecd875": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14bf2ab82bfc45bd8a3b93f2ab9aa656",
      "placeholder": "",
      "style": "IPY_MODEL_9fc9479d78e442db91360de7f45b6d7f",
      "value": "Downloading: 100%"
     }
    },
    "bac8f28c84144450b24bbc97fa4860db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ddf20490dc874352aa7df35f07a60bcc",
      "placeholder": "",
      "style": "IPY_MODEL_f9390d4fc9b147729f1ef5ea85d03774",
      "value": "Downloading: 100%"
     }
    },
    "be6339f6256d4b579c53ef8b430ecb25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf127a02cf6647aba4035c5cbfadc378": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0f0d9a0d4f4440e81e5a6d5a2a3b4ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3a13b7869354881ac7b7887e05d56a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_870fe8f58bb24a47b6a98fa0eed0ebf5",
       "IPY_MODEL_193a5a054d6f4a319842820c4c308322",
       "IPY_MODEL_5a478b81997c4263a60d938447232fd9"
      ],
      "layout": "IPY_MODEL_4d22913664fb4cdbb38e217d4197601d"
     }
    },
    "d7bef2816920414f99a5c9cc676ec254": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d8b619dff35e4f8cabf586221ad8c962": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ddf20490dc874352aa7df35f07a60bcc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec76cfd2d1da498e9b66885ff1be46b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f41b83ccf26c40ed88ca6eaf49e09de5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9390d4fc9b147729f1ef5ea85d03774": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
